{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Exercise (early draft for internal experimentation)\n",
    "\n",
    "Instructions and some steps pending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install git+https://github.com/facebookresearch/fastText.git \n",
    "!pip install 'git+https://github.com/chrka/cip-tagging-exercise.git#egg=tagger&subdirectory=source'\n",
    "!wget http://citypolarna.se/event_data.csv -O /tmp/raw.csv\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/chrka/anaconda3/envs/tagging-exercise/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/chrka/anaconda3/envs/tagging-exercise/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/chrka/anaconda3/envs/tagging-exercise/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/chrka/anaconda3/envs/tagging-exercise/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/chrka/anaconda3/envs/tagging-exercise/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/chrka/anaconda3/envs/tagging-exercise/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tagger import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://citypolarna.se/event_data.csv -O \"../data/raw/citypolarna_public_events_out.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/chrka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tagger.dataset.cleaning import load_datasets\n",
    "\n",
    "events_train, tags_train, events_test, tags_test, top_tags = load_datasets(\n",
    "    \"../data/raw/citypolarna_public_events_out.csv\")\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "* `ExtractText(columns=['description'], add_time_of_day=False)`: (Data frame to HTM) Extract text fields from event data into a single string vector.  Optionally prepends special symbols for time of day (or all-day) as appropriate.\n",
    "* `HTMLToText()`: (HTML to string) Converts HTML into raw text.\n",
    "* `CharacterSet(punctuation=True, digits=False)`: (String vector to string vector) Keeps alphabetic characters and collapses multiple whitespaces into single.  Optionally keeps digits and punctuation.\n",
    "* `Lowercase()`: (String to string) Converts all alphabetic characters into their lowercase equivalents.\n",
    "* `Tokenize(method='word_punct)`: (String to token list) Splits strings into lists of tokens.  If method is `whitespace`, whitespaces are used for splitting, if `word_punct` (default), punctuation marks are also used for splitting.\n",
    "* `Stopwords()`: (Token list to token list) Removes stop words.\n",
    "* `Stemming()': (Token list to token list) Converts tokens into their stems.\n",
    "* `NGram(n_min, n_max=None)`: (Token list to token list) Create all $n$-grams from $n_{\\mathrm{min}}$-grams to $n_{\\mathrm{max}}$-grams. (If no $n_{\\mathrm{max}}$, only $n_{\\mathrm{min}}$-grams are created.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocessing = Pipeline([\n",
    "    ('fields', ExtractText()),\n",
    "    ('html', HTMLToText()),\n",
    "    ('cset', CharacterSet(punctuation=False)),\n",
    "    ('lower', Lowercase()),\n",
    "    ('token', Tokenize())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7318    [vi, är, några, som, tänkt, fika, på, söndag, ...\n",
       "9088    [hej, då, var, det, dags, för, en, bokklubbstr...\n",
       "4793    [pröva, på, att, dansa, kizomba, prova, på, kl...\n",
       "4553    [på, fredag, är, det, premiär, för, grand, hot...\n",
       "6068    [uppdatering, dddd, dd, dd, ändrat, sista, dat...\n",
       "1732    [intressekoll, inför, kvällen, trädgårn, klubb...\n",
       "8802    [hej, minsta, rundan, ever, haha, men, då, får...\n",
       "9183    [missa, inte, denna, intima, och, självutlämna...\n",
       "6929    [någon, som, vill, med, till, hävringe, fyr, f...\n",
       "4779    [obs, det, riskerar, att, bli, fullt, eller, n...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preprocessing.fit_transform(events_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preprocessing = Pipeline([\n",
    "    ('fields', ExtractText(['title', 'description'], add_time_of_day=False)),\n",
    "    ('html', HTMLToText()),\n",
    "    ('cset', CharacterSet(punctuation=False, digits=False)),\n",
    "    ('lower', Lowercase()),\n",
    "    ('token', Tokenize()),\n",
    "    ('stop', Stopwords()),\n",
    "    ('stem', Stemming()),\n",
    "    ('ngram', NGram(1, 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fik',\n",
       "  'tänk',\n",
       "  'fik',\n",
       "  'söndag',\n",
       "  'häng',\n",
       "  'vill',\n",
       "  'ring',\n",
       "  'komm',\n",
       "  'dd',\n",
       "  'förklar',\n",
       "  'dddd',\n",
       "  'fik tänk',\n",
       "  'tänk fik',\n",
       "  'fik söndag',\n",
       "  'söndag häng',\n",
       "  'häng vill',\n",
       "  'vill ring',\n",
       "  'ring komm',\n",
       "  'komm dd',\n",
       "  'dd förklar',\n",
       "  'förklar dddd']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(my_preprocessing.fit_transform(events_train[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "* `BagOfWords(binary=False)`: (List of tokens to sparse vector) Create bag of words vectors.  If `binary=True`, ignore counts and only indicate if word is present or not.\n",
    "* `Tfidf()`: (List of tokens to sparse vector)\n",
    "* `SumWordBedding(model_path)`, `MeanWordBedding(model_path)`: (List of tokens to sparse vector) Convert tokens to sum respective mean of their word embedding vectors.\n",
    "* (`WordEmbedding()`: (List of tokens to matrix))\n",
    "* `SparseToDense()`: (Sparse vector to vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = Pipeline([\n",
    "    ('bow', BagOfWords())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_features = Pipeline([\n",
    "    ('bow', BagOfWords(binary=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithms\n",
    "\n",
    "* `NaiveBayes()`: ((Sparse) Vector to prediction) Naïve Bayes\n",
    "* `LogisticRegression()`: ((Sparse) Vector to predictions) Logistic regression\n",
    "* `MultiLayerPerceptron(layers, epochs=16, batch_size=64)`: (Vector to prediction) Multi-layered perceptron with specified layers, eg., `layers=[1024, 256]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_classifier = Pipeline([\n",
    "    ('nb', NaiveBayes())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier = Pipeline([\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "* `evaluate_per_label(model, top_tags, events, tags, test_size=0.2, sample_size=None, n_splits=3, random_state=42)`: Calculate per-label stats for the given model, using $n_{\\mathrm{n_splits}}$-fold cross validation.\n",
    "\n",
    "Model comparisons, and visualizations coming later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = Pipeline([\n",
    "    ('pre', baseline_preprocessing),\n",
    "    ('feat', baseline_features),\n",
    "    ('clf', baseline_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.06 s, sys: 69.5 ms, total: 3.13 s\n",
      "Wall time: 3.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pre', Pipeline(memory=None,\n",
       "     steps=[('fields', ExtractText(add_time_of_day=False, columns=['description'])), ('html', HTMLToText()), ('cset', CharacterSet(digits=False, punctuation=False)), ('lower', Lowercase()), ('token', Tokenize(method='word_punct'))])), ('feat', Pipeline(memory=None, steps=[('bow', BagOfWords(binary=False))])), ('clf', Pipeline(memory=None, steps=[('nb', NaiveBayes())]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "baseline_model.fit(events_train, tags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Pipeline([\n",
    "    ('pre', my_preprocessing),\n",
    "    ('feat', my_features),\n",
    "    ('clf', my_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 8s, sys: 2.71 s, total: 5min 11s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pre', Pipeline(memory=None,\n",
       "     steps=[('fields', ExtractText(add_time_of_day=False, columns=['title', 'description'])), ('html', HTMLToText()), ('cset', CharacterSet(digits=False, punctuation=False)), ('lower', Lowercase()), ('token', Tokenize(method='word_punct')), ('stop', Stopwords()),... BagOfWords(binary=False))])), ('clf', Pipeline(memory=None, steps=[('lr', LogisticRegression())]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "my_model.fit(events_train, tags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1344d3b2dd4ef289a68333b8e72f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "stats = evaluate_per_label(my_model, top_tags, events_train, tags_train)\n",
    "stats.sort_values('auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "* `submit_model(model, *, team_name, model_name, local_events=None, local_tags=None)`:  Evaluate and submit model predictions to leaderboard.\n",
    "\n",
    "For now, only local evaluation is available, which can be used for model comparisons for now,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_model(baseline_model, \n",
    "             team_name=\"All your base are belong to us\",\n",
    "             model_name=\"baseline\",\n",
    "             local_events=events_test,\n",
    "             local_tags=tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_model(my_model, \n",
    "             team_name=\"Little gray cells\",\n",
    "             model_name=\"1-2-gram\",\n",
    "             local_events=events_test,\n",
    "             local_tags=tags_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
