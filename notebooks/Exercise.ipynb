{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CiP Tagging Exercise\n",
    "\n",
    "In this exercise you will try your hand at assembling an NLP pipeline suggesting tags for [Citypolarna](https://www.citypolarna.se) events.\n",
    "\n",
    "You will be working with a dataset consisting of descriptions of past events which has already been tagged previously, using them to train a classifier to suggest tags for new and unseen events.\n",
    "\n",
    "Note that an event may have more than one tag. For example, it may both have **mat** (Swedish for \"food\") and **konsert** (\"concert\") for an event where you grab a bite before going to a concert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first step is to import the packages and data we need for the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Run the cells below to install the necessary packages and download the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THESE BEFORE EXPORTING TO COLAB\n",
    "#!pip install git+https://github.com/facebookresearch/fastText.git \n",
    "#!pip install 'git+https:x//github.com/chrka/cip-tagging-exercise.git#egg=tagger&subdirectory=source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tagger import *\n",
    "\n",
    "DATASET_URL = \"https://cip-tagging-exercise.ngrok.io/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tagger.dataset.external import load_external\n",
    "\n",
    "events_train, tags_train, events_test, top_tags, tags_train_stats = load_external(\n",
    "    \"https://cip-tagging-exercise.ngrok.io/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief overview of the data\n",
    "\n",
    "> Feel free to skip through this section and refer back to it only when if you have questions about the format of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the events are contained in the data frames `events_train` (for training your tagger) and `events_test` (events with unkown tags used in the final evaluation). \n",
    "\n",
    "The structure of the data frames is as follows:\n",
    "\n",
    "| Field       | Description                              |  \n",
    "| ----------- | ---------------------------------------- |  \n",
    "| id          | ID of the event                          |  \n",
    "| weekday     | Day of the week (0 = Monday, 6 = Sunday) |  \n",
    "| time        | Time of day (or _NA_ if an all-day event |  \n",
    "| title       | Event title                              |  \n",
    "| description | Event description (HTML)                 |  \n",
    "\n",
    "The text fields — `title` and `description` — are probably the most important for figuring out which tags should be suggested, and the ones we will be focusing on in this exercise.  But you might like to think about how the other fields could prove to be useful as well.\n",
    "\n",
    "This is what the data for the first couple of events look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have training data for about 7000 events and will be testing on about 2300 events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier will be trained to suggest labels from the following list of tags (shown with their respective counts in the training dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags for the events in the training data are available in `tags_train` in matrix form with a row for each event, and where a `1` in the $n$-th column means that the $n$-th tag (in the order given by `top_tags`) was applied for that event.\n",
    "\n",
    "This is what it looks for the first 5 events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TODO**: Add matrix_to_tags to make this simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(top_tags)[(tags_train[0:1] > 0).squeeze()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Now we get to the part where you actually get to put together uour classifier.\n",
    "\n",
    "The classifier consists of three different parts:\n",
    "\n",
    "* First, the **preprocessor** which extracts text data from the event data and turns it into tokens, to be used in the next step:\n",
    "* the **feature extractor** which in turn converts the tokens into numerical data, suitable for use in\n",
    "* a **Machine Learning algorithm** which learns what tags might be suitable for which events.\n",
    "\n",
    "The pipeline is built up out of a sequence of **transformers**, each of which does something to the data before passing it onto the next.  At the end of the pipeline, we put our **ML algorithm**.\n",
    "\n",
    "We define the pipeline as a list of tuples (each being a **name** and the **transformer**/**algorithm** for the step.)\n",
    "\n",
    "To have something to compare your classifier against, we have also provided a baseline classifier.\n",
    "\n",
    "> **NB.** Take care that the output of each step matches the input of the next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The first task of the pipeline is to extract the text from the event data, and turn it into a series of tokens.\n",
    "\n",
    "The following transformers are suitable for this:\n",
    "\n",
    "`ExtractText(columns=['description'])`: (_Data frame to HTML_) Extract text fields from event data joined together. By default it only takes the descriptions, but by specifying the `columns` argument you can add other fields as well, eg., `columns=['title', 'description']` to join the titles and descriptions toghether.\n",
    "\n",
    "`HTMLToText()`: (_HTML to string_) The descriptions are HTML formatted, so we need a way to convert them into raw text without any formatting data.\n",
    "\n",
    "`CharacterSet(punctuation=True, digits=False)`: (_String to string_) Keeps alphabetic characters (Swedish) and collapses multiple whitespaces into single.  Optionally keeps digits and punctuation.  (Digits have been removed from this particular dataset already however.)\n",
    "\n",
    "`Lowercase()`: (_String to string_) Converts all alphabetic characters into their lowercase equivalents.\n",
    "\n",
    "`Tokenize(method='word_punct)`: (_String to token list_) Splits strings into lists of tokens.  If method is `whitespace`, whitespaces are used for splitting, if `word_punct` (default), punctuation marks are also used for splitting.\n",
    "\n",
    "\n",
    "\n",
    "`Stopwords()`: (_Token list to token list_) Removes stop words (the most common words in the Swedish language).\n",
    "\n",
    "`Stemming()`: (_Token list to token list_) Converts tokens into their stems.\n",
    "\n",
    "`NGram(n_min, n_max=None)`: (_Token list to token list_) Create all $n$-grams from $n_{\\mathrm{min}}$-grams to $n_{\\mathrm{max}}$-grams. (If no $n_{\\mathrm{max}}$, only $n_{\\mathrm{min}}$-grams are created.)\n",
    "\n",
    "> Of these steps, `ExtractToText()`, `HTMLToText()`, and, `Tokenize()` are most likely necessary to include in the pipeline, but do try to experiment a little with the other ones as well.\n",
    "\n",
    "We'll assemble each step of the classifier into a separate [scikit-learn](https://scikit-learn.org/) pipeline so that we can try them out separately if we want to.\n",
    "\n",
    "> The details of Pipelines are not terribly important right now, but it might be useful to know that we can `fit` them to data, and in the case of transformers, we can use them to `transform` data (after they've been fitted) — classifiers can be used to `predict` (once again, must be fitted first).  As a shortcut, one can also `fit_transform` to fit and transform the same data in one single step.\n",
    "\n",
    "The baseline model extracts text, converts it from HTML into raw text, removes any non-alphabetic characters — even removing punctuation — and breaks the text into tokens after converting everything into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocessing = Pipeline([\n",
    "    ('fields', ExtractText()),\n",
    "    ('html', HTMLToText()),\n",
    "    ('cset', CharacterSet(punctuation=False)),\n",
    "    ('lower', Lowercase()),\n",
    "    ('token', Tokenize())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a quick peek at what the baseline's preprocessing steps do (and we do see that it does what we'd expect):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocessed = baseline_preprocessing.fit_transform(events_train.head())\n",
    "baseline_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Now it's your turn to add your own preprocessing steps below.  We have already added the ones that are required.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preprocessing = Pipeline([\n",
    "    ('fields', ExtractText()),\n",
    "    ('html', HTMLToText()),\n",
    "    # YOUR STEPS HERE\n",
    "    ('token', Tokenize())\n",
    "    # YOUR STEPS HERE\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "In order to convert the tokens into numerical data suitable for a machine learning algorithm, you could try one of the following common methods.\n",
    "\n",
    "`BagOfWords(binary=False)`: (_List of tokens to sparse vector_) Counts the occurences of each word in the list of the tokens, and creates a vector out of them.  If the argument `binary` is set to `True`, then it only cares if a token occurs or not (ie., it gives it a count of either 1 or 0).\n",
    "\n",
    "> That the result is a _sparse vector_ means that the result only specifies non-zero entries.  When zeros are included as well, it is called a _dense vector_.  Since some implementations of ML algorithms do not work well with sparse vector, we have also provided a `SparseToDense()` transformer below.\n",
    "\n",
    "`Tfidf()`: (_List of tokens to sparse vector_) Similarly to `BagOfWords`, it also counts the occurences of each token, but instead creates a vector of each token's _term frequency_ (how often the token occurs in the event description) multiplied by its _inverse document frequency_ (one divided by the number of descriptions the token occurs in).  The intuition being that the more often a token occurs in a description the more likely it is that it is representative of that event, while at the same time considering that if the token occurs in many, many events, it is probably not specific to the the event.\n",
    "\n",
    "`SumWordBedding()`, `MeanWordBedding()`: (_List of tokens to sparse vector_) A different way of converting words to vectors is to use what is known as a _word embedding_. Each word is converted in such a way that words that occur in a similar context, result in vectors that are near each other.  The simplest way of using these are by adding the vectors together for all words (or taking their means).\n",
    "\n",
    "> **NB.** We have precomputed word vectors from the event dataset based on regular words only (no punctuation, lowercase only) so will probably not work very well with n-grams etc.\n",
    "\n",
    "Some other transformers that can be useful for dealing with feature vectors:\n",
    "\n",
    "`SparseToDense()`: (_Sparse vector to dense vector_) Converts a sparse vector to a dense vector with the same contents.  Necessary, for example, for classifiers using the `MultiLayerPerceptron()`.\n",
    "\n",
    "`MaxAbsScaler()`: (_Sparse/dense vector to sparse/dense vector_) Scales the elements of a vector to be in the range $[-1, 1]$ such that the absolute maximum value of each column (over all training samples) is 1.  This can increase the performance of certain ML algorithms, such as `LogisticRegression()`.\n",
    "\n",
    "The baseline model uses bag of words, plain and simple.\n",
    "\n",
    "> If you have experience with [scikit-learn](https://scikit-learn.org/), you may want to try out some other ways of manipulating your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_feature_extraction = Pipeline([\n",
    "    ('bow', BagOfWords())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can once again take a quick look at what the baseline does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_feature_extraction.fit_transform(baseline_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that it results in a sparse matrix for a couple of hundred tokens (since we only look at the first couple of events for this example, the number of distinct tokens won't be that large)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Once again, it's your turn! Define your feature extraction steps here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_extraction = Pipeline([\n",
    "    # YOUR STEPS HERE\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Plenty of algorithms could be used, but here are a couple of suggestions:\n",
    "\n",
    "`NaiveBayes()`: ((Sparse) Vector to prediction) Naïve Bayes\n",
    "\n",
    "`LogisticRegression()`: ((Sparse) Vector to predictions) Logistic regression\n",
    "\n",
    "`MultiLayerPerceptron(layers, epochs=16, batch_size=64)`: (Vector to prediction) Multi-layered perceptron with specified layers, eg., `layers=[256, 256]`)\n",
    "\n",
    ">  There are many other algorithms in [scikit-learn](https://scikit-learn.org/) you can try if you have some experience.  (Since this is a multi-label problem, you might find [OneVsRestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) useful.)\n",
    "\n",
    "The baseline uses Naïve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_algorithm = Pipeline([\n",
    "    ('nb', NaiveBayes())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pick your algorithm and define the final step of your classification pipeline below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_algorithm = Pipeline([\n",
    "    # YOUR STEPS HERE\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling the pipeline\n",
    "\n",
    "It's now time to put together preprocessing, feature extraction, and the algorithm into a single pipeline.\n",
    "\n",
    "> **Run the cells below to complete the pipeline for the baseline classifier, and your own.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_classifier = Pipeline([\n",
    "    ('pre', baseline_preprocessing), \n",
    "    ('feat', baseline_feature_extraction), \n",
    "    ('algo', baseline_algorithm)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier =  Pipeline([\n",
    "    ('pre', my_preprocessing), \n",
    "    ('feat', my_feature_extraction), \n",
    "    ('algo', my_algorithm)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "You will now try out your model by training it on a subset of the training data only, and evaluating its performance on the remainder of the data.  This should give you some idea of how well it will perform on unseen data.\n",
    "\n",
    "The two main metrics the model will be evaluated on are:\n",
    "\n",
    "* **Hamming loss**: The fraction of tags that either are suggested when they shouldn't be, or aren't suggested when they should. (It ranges from 0–1, lower is better.)\n",
    "* **Exact match ratio**: The fraction of events that have been completely correctly classified, that is, precisely those labels that should be suggested for the event has been suggested, and no others. (Also ranges from 0–1, but here higher is better.)\n",
    "\n",
    "It can also be interesting to take a look at how well the classifier works with individual labels, so **accuracy** (how often a predicted tag matches the actual tag), **precision** (how often a suggested tag is correct), **recall** (how often an actual tag is predicted), and **$F_1$-scores** (harmonic mean of precision and recall) are reported for the individual tags as well. (Since any given tag occurs pretty rarely, accuracy is not that important since always predicting that tags shouldn't occur is correct much more often than not.)\n",
    "\n",
    "> For the sake of simplicity, the classifier only predicts whether or not a tag should be added to an event.  A more realistic case would be to instead predict the _probability_ of a tag being appropriate for an event.\n",
    "\n",
    "> **Run the cells below to evaluate the performances of the baseline classifier as well as your own.  How do they compare?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_classifier(baseline_classifier, top_tags, events_train, tags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_classifier(my_classifier, top_tags, events_train, tags_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Once you have found a sequence of steps you think performs well, it's time to train it on the full training set, and submit its prediction on the (secret!) test set.\n",
    "\n",
    "> **When you're satisifed with the performance of your classifier, first edit the cell below to add your team name and a brief description of your model, and then run it to see how well it performed compared to the other participants'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_classifier.fit(events_train, tags_train)\n",
    "\n",
    "SUBMISSION_URL = \"https://cip-tagging-exercise.ngrok.io/\"\n",
    "\n",
    "submit_model(my_classifier,\n",
    "             team_name=\"<INSERT TEAM NAME HERE>\",\n",
    "             model_name=\"<INSERT MODEL DESCRIPTION HERE>\",\n",
    "             events=events_test,\n",
    "             base_url=SUBMISSION_URL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
